Latif Yahia - Emotional AI chatbot Journal

29/10/2020
Today i got feed back on my project proposal form Paul and was informed it all looked good. Next step for me to take is read over the proposal one final time then submit it later today or tomorrow the 30th of october.

30/10/2020
Today is the dealline for our project proposal. I showed my propsoal to Brian today and got some feed back on my architecture diagram. After making some changes to my architecture diagram i finally submitted my project proposal.

04/11/2020
Today i decided to change some thing within my project design. Instead of using a esp32 with camera module i decided to use a normal webcam for facial recognition as an EPS32 is really not nessesary for my project. I consulted paul and brian and they seem to be okay with it. I updated my project proposal and subbmitted again.

18/11/2020
Last week for the 9th of november i forgot to update my log for the research that i was doing on docker containers and how they work as im playing on setting up everything on my local server on a docker container and have all the work transfered to my AWS after christmas within the container. This week i couldnt really get much done as im pretty busy with assignments.

24/11/2020
Today i installed ubuntu with python and docker. I also installed django and got my webserver running on my localhost. Im having trouble trying to understand docker as its not working correctly for me. I will conintue to research this and find a solution.

03/12/2020
This week i tried resolving some issues i was having with docker but i was unsuccessful. Im going to skip over docker for now and continue working on django and rasa. I also have ordered my webcam off amazon so i can start working on the azure facial recognition.

08/12/2020
I installed rasa and have got the sample code for the chat bot working. I can interact with the bot via a terminal. I have also installed azure facial recognition but i havnt got that set up properly yet. im hoping to have it verifying faces soon. I will be using example code to test and make sure if the azure facial recognition is set up correctly.

17/12/2020
I havent been working on my project over the past week as ive had alot of assignments and exams coming up. I plan on working on the project during christmas break 

01/01/2021
Over the past two week i was very busy with assignments and coding exams which didnt give me much time to work on this project. I startred where i last left off which was installing azure facial recognition. Im running into a few problems with my webcam but currentlyu havent found a soultion for it. I plan to continue 
working on this until i fix it. As soon as i get the problem fixed i will be able to start detecting faces and emotions using azure api. I then will start development on the bot to improve it.

05/01/2021
Over the past couple days i was focusing on getting azure facial recognition to work. Using sample code form microsoft i have it decting emotions from images but currently looking on how to get 
it to detect emotions from a live stream which is alot more complicated.I also focused on getting my webcam stream onto my localhost server. This was fairly time consuiming as to do that i had to do
alot of more stuff with djano like setting up templates for pages, setting url patterns and writing some simple code into views.py. I done alot of research in order to do this as can be seen in the research.txt 
reference. Over the past few days i broke my ubuntu which caused to have alot of errors using it. I spent about 7-8 hours trying to fix it which i did. I also spent alot of time figuing out how to install the python packages for azure 
in inteliji as i was going to need them. There isnt much infomation out there on this matter which caused me to spend several hours on it. I was initalling the lastest mega library from azure which kept causing my python to crash and give me errors
which was weird because all other packages where being installed fine. After digging around on github i found out there was a problem with the python package lastest version which i than just installed the previous version which was 4.0.0. I was happy 
i finally got it done and somewhat working. I havnt touched the chatbot yet as i feel i can do that very easily just to get it to commuicate better before the presentation hence wy i was focued more on the azure and django stuff.
I plan to hopefulyl get the azure facial recognition working with my webcam stream before the presentaitons aswell as have the bot commiucate somehow with a human.

08/01/2021
made alot of changes to the bot and now have it communicatig to the user where it will ask users name and reply with to the user with their name and ask about how theyre day is etc etc. 
Im only currently working on the happy path and have no started on other emotions yet. I change alot of the NLU data aswell and started righting custom actions for slop mapping in order to take users name 
aswell as if theyre happy and why theyre happy. Still alot of work to be done on the happy path and im no where were id like to be but im finding this challeneging which is good i guess.

09/01/2021
Today i progressed with rasa. I used a sample chatbox for my website which i got from github off a rasa developer. This means my bot can now communicate with you via my website through the bots API which 
is pretty cool as before i was only able to communicate with the bot via shell. I ran into a lot of problems trying this as i had to set up static files for django which is okay because i had to
do that at somepoint within this project. I also changed something with the azure facial recognition. Now i can get a link to any photo online and get the emotions displayed in that photo. I tried  capturing a photo from my webcam and using that to detect emotions but 
it didnt work and im now abit stuck. I feel like i made good progress today and my presentation will go well with what i have currently working. There is still alot to do and its going to be very challenging as right now its already tough.

10/01/2021
Today i finizled some changes for my christmas demo. I made my video demo but i feel as the timeframe we were giving was too little to go through everything and all the work i had done doesnt seem like it got covered. I have uploaded my video
and my questionaire. 

27/01/2021
I have research ways to try get azure face to detect emotions through live feed but havnt really found anything and if i have they are just too complicated for what im trying to do. Im thinking of taking snapshots of my webcam live feed 
and saving the images to my server for processing. This way i can bacially detect emotions through a feed. Its not the best way but im trying to give it a go anyways to see if it even works.

02/02/2021
Ive been trying to figure out how to save images on my localhost server then analyze those images for dections. Im making abit of progress but not as much as id like to. Im hoping to get this done by the end of next week and start working on converstaion paths.
Ive been looking online on how to do this but there really isnt much out there as im going to need a image URL for the image to detect the emotions and im not sure if thats even possible.

10/02/2020
Ive figured out how to save images to my computer in order to analyze them for facial dectection. Ive ran into a problem regarding AWS. I havent been able to sign up for it as a student as use it for free like 
i was told i would be able to do from one of my lectures. Since im not able to use AWS, ive left the whole saving images to the computer/server since id have to redo it all when talking about saving it
to the server.

16/02/21
For the past few days ive added more NLU data to the chatbot. While i was adding NLU data i started thinking on how to actually get the emotioned across to the bot. Im thinking of writing python code in the
actions.py file that will need a requested slot to be filled. If i fill the json data that i get into these slots and depending on the emotion recieved the bot will be able to talk in different ways. I will 
also have to do alot of work in stories to get all the right paths for the converstaion right. Im slowly progressing step by step

23/02/21
I decided to go back to trying to save an image to my local host since i was informed not to start the transfer my project to aws yet by one of my lectures since he was going to show us how to do it
the following monday. I looked through the web to see if there was a way to do and i came across a few ways but everything required the use of PHP which just wasnt working for me. I spent nearly 5 hours trying to get it to work but i got no luck.
Apprently django and PHP dont seem to get along together too well and there isnt much explaination out their on the subject. I kept getting a url reference error saying the url was not defined yet i had it defined and my other urls work. im literally 
at a point where i dont know what to do from here? should i maybe use another techonolgy thats no Azure which might make facial decetion with a live camera feed work instead of tyring to find this whole way of saving images and trying to idenitify emotions that way
Im really not sure what to do but ill keep researching what i can do.

02/03/21
I decided to stop using azure face to dection emotions as its hard to work with in python as its mainly used in C++. I tried saving photos to the server and using the image link to detect emotions that way but i kept running into other problems. 
I came accross a faceial recogintion API library thats written in javascript. I started working with it and im now able to detect emotions through my live camera feed. Its a great API thats eays to use. I read about it online and watch some tutorials on how to use it.
I downloaded some models to use for the API and everything works great. Im getting all the emotion data into an array in javascript which i will then have to send across to python  probably using jquary and json which i havent figure out how to do yet but im making
progress and im pretty happy that i have that working now.

09/03/21
This week i havent really had time to work on the project has i have been trying to start 3 other miniprojects aswell as i had 3 exams coming up which i studied for. I plan to start the miniprojects for other modules and finish these exams before returning to work on
this project. Ive also just been looking around on how to send a jquary from the face-api to django nothing major.

16/03/2021
Unfortunitally i hadnt had time to work on my project this week as ive been working on other miniprojects. Im still looking over stuff for my project and taking note of things to do when i get back to working on it as to save myself time 
from having to look up all the stuff to do. I think ive figured out how to transfer the data from js to my views.py and then over to rasa. Its only a matter of writing the code. 

23/03/21
I did some reserch on json and how i would go about formating the facial expressions i was getting in my json object. I can now format the data i want through javascript and pass that data along to a hidden html text input field where i will later go a get request o that field 
in order to pull the facial expression of the person that is seen on the webcam. That emotion will later be passed to rasa where the bot will require a slot called emotion before any message are sent back. This way the bot will talk to the person depending on the 
emotions it detects. Good progress so far this week and i dont plan on stopping. As soon as i get going its hard to stop. 

28/03/21
I did some more coding in my javascript function to extract and send the emotions being displaye by the user. I now have the emotion thats being displayed if the model detects that an emotion is being displaced thats greater
than 50%, it would send over the emotion to a hidden html text input field. I will later try to retreive this value from the hidden input text field and pass it across to rasa. I also
changed some of the actions in rasa to try retrive this emotion but no luck yet.

30/03/21
**Also made a mistake last commit, i put date as 08/03/21, instead of 28/03/21**
I tried to pass the current emotion diaplyed through django but unfortunallty i didnt get anywhere. I started looking at different soultion to try do this. Passing data from Django to Rasa is hard since RASA 
only really likes to get json data and my current emotion displayed wasnt in json format. After doing heavy research, i came to the conclusion that i am doing to use NodeJS to set up a fake REST API on my 
localhost:3000 port to put json data onto a server. This allows me to access the Json data on the json-server and use it within RASA. I am using Axois to change the data on the json server and am constantly 
updating it with the current emotion displayed. This later allows me to always  get the current emotion displayed. Im doing all of this constantly in order to always have the current emotion being updated live.
I now have my Face-Api detecting the emotion displayed every 5 second. Im than sending that emotion to a Json server which i will later than get within RASA and fill it as a requested slot. I made alot of progress today
and am very happy with myself. It should be a pretty straight road from here on. I also removed some code within the home page, i removed the input textfield since i no longer require it aswell as i made some changes 
within RASA trying to get data from django. Also, i thought of using the Django REST API but after doing some research i came to the conclusion that its to much work and would instead rather use a fake rest api 
like a json-server running on nodeJS, which in the end was easier and less time consuming.

06/04/2021
I now have a custom action that pull the current emotion being displayed into RASA. This custom action also fills a slot in RASa which i can later than use to drive converstaion in a certain way. Currently im having problems relating to slots in my stories,
since the my stories arent being followed. Ive posted on RASA community forms seeking assistance and am waiting to hear back. Today i made good progress again but not where i wanted to be by the end of this coding session. Im nearly there so i dont mind putting in the work.
I also cleaned up my RASA code so its easier to work with and i added alot of more policys for the chatbot to follow. All in all the bot looks good apart from that one problem. As soon as i fix that problem i would have my project finished within 2 weeks.

07/04/2021
I got a reply from a RASA developer regarding my issue of my stories in rasa not being followed depending on the slot value set. The RASA developer told me to change the slot value type from 'text' to 'catagorial'. This 
ended up fixing my issue i was having. Now rasa will follow the stories i wrote depending on the different slot value which is set for emotion. This is great because now i can just bang out the whole code without worrying about any more problems. The foundation for my code is there
now i must write it.

20/04/2021
Started adding bottstrap to my html code to better style my website. Im trying to finish all the styling and make it look professional before proceeding anymore. Styling my website and finishing all the webpages now
is a good idea in my view.

20/04/2021
added user registeration app to my django project which allows a user to login,logout or register if they done have an account. I used djangos built in authentication system to do this with the help from some online sources. 
I Also set up the django database to save users info. I also set up a database tabel with emotions that can be sent in by different users who are logged in. This will allow me to extract these emotions depeneding on the user and 
chart them later to add more funcionality to my website. I also done alot of styling and started using bootstrap5 to do my styling. My website looks nice and clean now but not finished as there is still a good but more styling to do

22/04/2021
I created a user profiles page. Each user with an account will be able to access their own profile page. On this page, it will display personal information and emotions detected collected through live sessions of
using the chatbot. The facial regoniton will save each emotion detected by the user to djangos data base. I wrote a function to pull the current logged in users detected emotion from the django database then plot the 
percentage of emotions detected in different charts. I created the charts using chartsjs and i used jquary with ajax to send the emotions to the database. I also made sure people who are not logged in cannot access the profile page. I also added some very nice stlying to the profile
page. Users can toggle the charts to display them. I also added fade in and fade out animations for the charts for when their toggled. It adds lot more functionality ot my website and makes it look nice.


26/04/2021
i fixed the chat widget layout now its no londer overlapping the feature focus text. I also chanegd around the avatar images to somehting better and also now my static images load properly sinc ebefore they didnt work/load. I also did good amount of styling on the login/regisiter page 
aswell as the chatbot widget page. I also got the drop down on the widget to work now.

27/04/2021
I added sass and scss compiles to my django project so django would be be able to read scss files. I found a nice library for styling that used scss and i wanted to use it. Only problem is django is not ocnfigured to read scss files which is a pity so i just ended up
adding scss compilers to my django apps. I also done alotttttttttttttt of styling. I totally change the navigation bar at the top and also made my home page look very professional. My website is looking very veyr nice and im proud of it. I also renamed some html pages to
better suited names. Majority of the styling is now complete which means i can style all my pages now all i really have to do is copy and paste stuff. 

28/04/2021
Started using gsap to animate elements on  my website. I added alot of animations to my home page. I also styled and filled in my about page with feautres and general information. I created icons for these features using lucid charts which i downloaded as svg files. 
I also animated the about page. I changed around my animation on my profile page of the charts to use gsap instead of quary since i can do more with gsap. I also added checking to see if user is logged in to display different button on home page and aboutpage. Styling of 
the website is 90% done. I also added a nice backgroudn that fades into the navigation header. I also animated the navigation header. I also added some referencing to my code and referenced code i token from github repos and examples. Also ran a couple collect statics

29/04/2021
I styled the lolly page and also added animation to the page. I also added emotions that could be detected to the page and what ever emotion is being detected the color of the word changes to purple same colour as the website theme.I also added error checking to whether the facial recogition 
is detecting any faces. If no faces are being detect a error message will animate out and when the facial regcoition goes back the detecting faces the error message will animate out. I also am displaying different texts on the Lolly page depending on whether the users camera is on or off, 
having the camera off ill display text asking the user to enable it for the full experience. Having the camera 
on will display text regarding lolly and what the user can expect

30/04/2021
i styled the profile page and also added animation to it. The profile page looks very nice now. I also added more images to the website that i got for free from Updraw whichis an open source community for images for webdesign. I also have those new images on the home 
pag, about page and profile page animating in. I set it so that if youre on 1920x1080 that the images wont show becausethere would then be too much on the screen and the website wont look as clean. If youre on 3440x1440 the images than will show because therer would be
 alot of white space if the images didnt show. I also done some general work on the performce of the website because when i would go to the profile page or lolly page i would get white flickering which wasnt nice so i added a javascript function in the base.html to 
ensure that the html body has loaded beofre doing anything. The styling of the website is now 99% done i just have to add one more animation and im finished

30/04/2021 - Part 2
i ran the bot today to make sure it still working on the website but it turns out it stopped working because of an issue i was face earlier this year relating to cores policy when im passing data over from django to rasa. I ended up looking for a solution online but the default
mentioned of install django-cors-headers didnt work for me so i was lucky to find a soultion where another user was having the same problem. They ended up righting their own middle ware class for cors policy and posted it on stackoverflow which i took and put into my project.
No shame in takening his code to fix my own issue because the normal way of installing django-cors-headers just wasnting working i dont know why. Anyways after writing the class and putting it in my django app i was still having the same problems. Turns out since i was using chrome,
my cache was effecting cors policy so i opened up edge and tried it there and like magic it worked. I spent a good 2 hours on this issue but happy its resolved now

03/05/2021
Added alot more chatpaths and custom actions for rasa so the bot will be able to talk to the person dpeending on what emotions they first display. I also added material for the bot to use to cheer the user up. I still need to add more paths but im nearly done with it now. I also added user data to the profile page and also added 
first name and last name to the regisiteration which i later pull djangos database and put in on the profile of the user logged in. I also added error checking so a user who is logged in cannot access the register page

07/05/2021
I finished off the about page and change around a few things nothing major tho

08/05/2021
i finished all the paths for rasa. The bot will always now try to cheer the user up if they arent happy. It will check for the emotion after trying to cheer them upto see if the bot was successful.
If it isnt, it will try again. If again it didnt cheer them up it will send them link to articals on how to cheer up because the bot cannot go on forever, well it can, it takes more than 1 person to
create such a bot, im basically finished my project just need to finish some things up. Im 99% there
