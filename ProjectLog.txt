Latif Yahia - Emotional AI chatbot Journal

29/10/2020
Today i got feed back on my project proposal form Paul and was informed it all looked good. Next step for me to take is read over the proposal one final time then submit it later today or tomorrow the 30th of october.

30/10/2020
Today is the dealline for our project proposal. I showed my propsoal to Brian today and got some feed back on my architecture diagram. After making some changes to my architecture diagram i finally submitted my project proposal.

04/11/2020
Today i decided to change some thing within my project design. Instead of using a esp32 with camera module i decided to use a normal webcam for facial recognition as an EPS32 is really not nessesary for my project. I consulted paul and brian and they seem to be okay with it. I updated my project proposal and subbmitted again.

18/11/2020
Last week for the 9th of november i forgot to update my log for the research that i was doing on docker containers and how they work as im playing on setting up everything on my local server on a docker container and have all the work transfered to my AWS after christmas within the container. This week i couldnt really get much done as im pretty busy with assignments.

24/11/2020
Today i installed ubuntu with python and docker. I also installed django and got my webserver running on my localhost. Im having trouble trying to understand docker as its not working correctly for me. I will conintue to research this and find a solution.

03/12/2020
This week i tried resolving some issues i was having with docker but i was unsuccessful. Im going to skip over docker for now and continue working on django and rasa. I also have ordered my webcam off amazon so i can start working on the azure facial recognition.

08/12/2020
I installed rasa and have got the sample code for the chat bot working. I can interact with the bot via a terminal. I have also installed azure facial recognition but i havnt got that set up properly yet. im hoping to have it verifying faces soon. I will be using example code to test and make sure if the azure facial recognition is set up correctly.

17/12/2020
I havent been working on my project over the past week as ive had alot of assignments and exams coming up. I plan on working on the project during christmas break 

01/01/2021
Over the past two week i was very busy with assignments and coding exams which didnt give me much time to work on this project. I startred where i last left off which was installing azure facial recognition. Im running into a few problems with my webcam but currentlyu havent found a soultion for it. I plan to continue 
working on this until i fix it. As soon as i get the problem fixed i will be able to start detecting faces and emotions using azure api. I then will start development on the bot to improve it.

05/01/2021
Over the past couple days i was focusing on getting azure facial recognition to work. Using sample code form microsoft i have it decting emotions from images but currently looking on how to get 
it to detect emotions from a live stream which is alot more complicated.I also focused on getting my webcam stream onto my localhost server. This was fairly time consuiming as to do that i had to do
alot of more stuff with djano like setting up templates for pages, setting url patterns and writing some simple code into views.py. I done alot of research in order to do this as can be seen in the research.txt 
reference. Over the past few days i broke my ubuntu which caused to have alot of errors using it. I spent about 7-8 hours trying to fix it which i did. I also spent alot of time figuing out how to install the python packages for azure 
in inteliji as i was going to need them. There isnt much infomation out there on this matter which caused me to spend several hours on it. I was initalling the lastest mega library from azure which kept causing my python to crash and give me errors
which was weird because all other packages where being installed fine. After digging around on github i found out there was a problem with the python package lastest version which i than just installed the previous version which was 4.0.0. I was happy 
i finally got it done and somewhat working. I havnt touched the chatbot yet as i feel i can do that very easily just to get it to commuicate better before the presentation hence wy i was focued more on the azure and django stuff.
I plan to hopefulyl get the azure facial recognition working with my webcam stream before the presentaitons aswell as have the bot commiucate somehow with a human.

08/01/2021
made alot of changes to the bot and now have it communicatig to the user where it will ask users name and reply with to the user with their name and ask about how theyre day is etc etc. 
Im only currently working on the happy path and have no started on other emotions yet. I change alot of the NLU data aswell and started righting custom actions for slop mapping in order to take users name 
aswell as if theyre happy and why theyre happy. Still alot of work to be done on the happy path and im no where were id like to be but im finding this challeneging which is good i guess.

09/01/2021
Today i progressed with rasa. I used a sample chatbox for my website which i got from github off a rasa developer. This means my bot can now communicate with you via my website through the bots API which 
is pretty cool as before i was only able to communicate with the bot via shell. I ran into a lot of problems trying this as i had to set up static files for django which is okay because i had to
do that at somepoint within this project. I also changed something with the azure facial recognition. Now i can get a link to any photo online and get the emotions displayed in that photo. I tried  capturing a photo from my webcam and using that to detect emotions but 
it didnt work and im now abit stuck. I feel like i made good progress today and my presentation will go well with what i have currently working. There is still alot to do and its going to be very challenging as right now its already tough.

10/01/2021
Today i finizled some changes for my christmas demo. I made my video demo but i feel as the timeframe we were giving was too little to go through everything and all the work i had done doesnt seem like it got covered. I have uploaded my video
and my questionaire. 

27/01/2021
I have research ways to try get azure face to detect emotions through live feed but havnt really found anything and if i have they are just too complicated for what im trying to do. Im thinking of taking snapshots of my webcam live feed 
and saving the images to my server for processing. This way i can bacially detect emotions through a feed. Its not the best way but im trying to give it a go anyways to see if it even works.

02/02/2021
Ive been trying to figure out how to save images on my localhost server then analyze those images for dections. Im making abit of progress but not as much as id like to. Im hoping to get this done by the end of next week and start working on converstaion paths.
Ive been looking online on how to do this but there really isnt much out there as im going to need a image URL for the image to detect the emotions and im not sure if thats even possible.

10/02/2020
Ive figured out how to save images to my computer in order to analyze them for facial dectection. Ive ran into a problem regarding AWS. I havent been able to sign up for it as a student as use it for free like 
i was told i would be able to do from one of my lectures. Since im not able to use AWS, ive left the whole saving images to the computer/server since id have to redo it all when talking about saving it
to the server.

16/02/21
For the past few days ive added more NLU data to the chatbot. While i was adding NLU data i started thinking on how to actually get the emotioned across to the bot. Im thinking of writing python code in the
actions.py file that will need a requested slot to be filled. If i fill the json data that i get into these slots and depending on the emotion recieved the bot will be able to talk in different ways. I will 
also have to do alot of work in stories to get all the right paths for the converstaion right. Im slowly progressing step by step

23/02/21
I decided to go back to trying to save an image to my local host since i was informed not to start the transfer my project to aws yet by one of my lectures since he was going to show us how to do it
the following monday. I looked through the web to see if there was a way to do and i came across a few ways but everything required the use of PHP which just wasnt working for me. I spent nearly 5 hours trying to get it to work but i got no luck.
Apprently django and PHP dont seem to get along together too well and there isnt much explaination out their on the subject. I kept getting a url reference error saying the url was not defined yet i had it defined and my other urls work. im literally 
at a point where i dont know what to do from here? should i maybe use another techonolgy thats no Azure which might make facial decetion with a live camera feed work instead of tyring to find this whole way of saving images and trying to idenitify emotions that way
Im really not sure what to do but ill keep researching what i can do.

02/03/21
I decided to stop using azure face to dection emotions as its hard to work with in python as its mainly used in C++. I tried saving photos to the server and using the image link to detect emotions that way but i kept running into other problems. 
I came accross a faceial recogintion API library thats written in javascript. I started working with it and im now able to detect emotions through my live camera feed. Its a great API thats eays to use. I read about it online and watch some tutorials on how to use it.
I downloaded some models to use for the API and everything works great. Im getting all the emotion data into an array in javascript which i will then have to send across to python  probably using jquary and json which i havent figure out how to do yet but im making
progress and im pretty happy that i have that working now.

09/03/21
This week i havent really had time to work on the project has i have been trying to start 3 other miniprojects aswell as i had 3 exams coming up which i studied for. I plan to start the miniprojects for other modules and finish these exams before returning to work on
this project. Ive also just been looking around on how to send a jquary from the face-api to django nothing major.

16/03/2021
Unfortunitally i hadnt had time to work on my project this week as ive been working on other miniprojects. Im still looking over stuff for my project and taking note of things to do when i get back to working on it as to save myself time 
from having to look up all the stuff to do. I think ive figured out how to transfer the data from js to my views.py and then over to rasa. Its only a matter of writing the code. 

23/03/21
I did some reserch on json and how i would go about formating the facial expressions i was getting in my json object. I can now format the data i want through javascript and pass that data along to a hidden html text input field where i will later go a get request o that field 
in order to pull the facial expression of the person that is seen on the webcam. That emotion will later be passed to rasa where the bot will require a slot called emotion before any message are sent back. This way the bot will talk to the person depending on the 
emotions it detects. Good progress so far this week and i dont plan on stopping. As soon as i get going its hard to stop. 

28/03/21
I did some more coding in my javascript function to extract and send the emotions being displaye by the user. I now have the emotion thats being displayed if the model detects that an emotion is being displaced thats greater
than 50%, it would send over the emotion to a hidden html text input field. I will later try to retreive this value from the hidden input text field and pass it across to rasa. I also
changed some of the actions in rasa to try retrive this emotion but no luck yet.

30/08/21
**Also made a mistake last commit, i put date as 08/03/21, instead of 28/03/21**
I tried to pass the current emotion diaplyed through django but unfortunallty i didnt get anywhere. I started looking at different soultion to try do this. Passing data from Django to Rasa is hard since RASA 
only really likes to get json data and my current emotion displayed wasnt in json format. After doing heavy research, i came to the conclusion that i am doing to use NodeJS to set up a fake REST API on my 
localhost:3000 port to put json data onto a server. This allows me to access the Json data on the json-server and use it within RASA. I am using Axois to change the data on the json server and am constantly 
updating it with the current emotion displayed. This later allows me to always  get the current emotion displayed. Im doing all of this constantly in order to always have the current emotion being updated live.
I now have my Face-Api detecting the emotion displayed every 5 second. Im than sending that emotion to a Json server which i will later than get within RASA and fill it as a requested slot. I made alot of progress today
and am very happy with myself. It should be a pretty straight road from here on. I also removed some code within the home page, i removed the input textfield since i no longer require it aswell as i made some changes 
within RASA trying to get data from django. Also, i thought of using the Django REST API but after doing some research i came to the conclusion that its to much work and would instead rather use a fake rest api 
like a json-server running on nodeJS, which in the end was easier and less time consuming.

